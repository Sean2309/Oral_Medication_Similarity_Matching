{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import shutil\n",
    "from shutil import copy2\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = os.path.join(os.getcwd(), \"../Dataset/Oral Dose Forms\")\n",
    "\n",
    "\n",
    "# ============= CONFIGURATION =============\n",
    "input_dir = \"../Dataset/Oral Dose Forms/\"  # Current directory where images are stored\n",
    "output_dir = \"../Dataset/Labelled_Images_blisterPriority/\"  # Output directory\n",
    "csv_path = \"./label_summary_blisterPriority.csv\"\n",
    "priority = \"Blisters\"  # Change to \"Blisters\" if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique labels (ignoring augmentation): 3827\n",
      "\n",
      "=== Packaging Counts ===\n",
      "Box: 8820 images\n",
      "Blisters: 13620 images\n",
      "Bottle: 3548 images\n",
      "\n",
      "=== Dosage Counts (Top 10) ===\n",
      "10mg: 2716\n",
      "5mg: 1727\n",
      "100mg: 1604\n",
      "25mg: 1440\n",
      "50mg: 1392\n",
      "20mg: 1184\n",
      "200mg: 1080\n",
      "500mg: 1044\n",
      "250mg: 876\n",
      "UnknownDosage: 868\n",
      "\n",
      "=== Top 10 Medications ===\n",
      "Rosuvastatin_Tab_0: 192\n",
      "Losartan_Tab_0: 140\n",
      "Telmisartan_Tab_0: 128\n",
      "Sildenafil_Tab_0: 124\n",
      "Carvedilol_Tab_0: 116\n",
      "Acitretin_Cap_0: 112\n",
      "Rosuvastatin_Tab_1: 108\n",
      "Quetiapine_Tab_0: 108\n",
      "Enalapril_Tab_0: 108\n",
      "Finasteride_Tab_0: 108\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "else:\n",
    "    # Clear output directory before starting\n",
    "    for filename in os.listdir(output_dir):\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        try:\n",
    "            if os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "            else:\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {file_path}: {e}\")\n",
    "\n",
    "# ============= REGEX PATTERNS =============\n",
    "dosage_pattern = re.compile(r\"(?xi)(?:[0-9]+(?:\\.[0-9]+)?(?:mg|mcg|g|ml))|(?:[0-9]+\\s*unit)\")\n",
    "version_pattern = re.compile(r\"v(\\d+)\", re.IGNORECASE)\n",
    "aug_pattern = re.compile(r\"_aug_(\\d+)\", re.IGNORECASE)\n",
    "\n",
    "# ============= HELPER FUNCTION: PACKAGING DETECTION =============\n",
    "def determine_packaging(original_name: str, priority: str = \"Box\") -> str:\n",
    "    \"\"\"\n",
    "    Determine packaging type based on keywords.\n",
    "    - 'Bottle', 'btl', 'ml', 'sachet', and 'oral solution' are always classified as 'Bottle'.\n",
    "    - 'Box' and 'Blisters' are the main classification groups. If both are found, follow priority setting.\n",
    "\n",
    "    Args:\n",
    "        original_name (str): The filename to classify.\n",
    "        priority (str): Either \"Box\" or \"Blisters\". Determines precedence.\n",
    "\n",
    "    Returns:\n",
    "        str: The classified packaging type.\n",
    "    \"\"\"\n",
    "    lower = original_name.lower()\n",
    "\n",
    "    # Define keyword lists\n",
    "    bottle_keywords = [\"bottle\", \"btl\", \"ml\", \"sachet\", \"oral solution\"]\n",
    "    box_keywords = [\"box\", \"pack\"]\n",
    "    blister_keywords = [\"cap\", \"capsule\", \"blister\"]\n",
    "\n",
    "    # First, check if it's a \"Bottle\" (highest precedence)\n",
    "    if any(keyword in lower for keyword in bottle_keywords):\n",
    "        return \"Bottle\"\n",
    "\n",
    "    # Otherwise, check for \"Box\" or \"Blisters\"\n",
    "    found_box = any(keyword in lower for keyword in box_keywords)\n",
    "    found_blister = any(keyword in lower for keyword in blister_keywords)\n",
    "\n",
    "    if found_box and found_blister:\n",
    "        return priority  # Assign based on priority setting\n",
    "\n",
    "    if found_box:\n",
    "        return \"Box\"\n",
    "    if found_blister:\n",
    "        return \"Blisters\"\n",
    "\n",
    "    return \"Blisters\"  # Default category if nothing matches\n",
    "\n",
    "# ============= MAIN SCRIPT =============\n",
    "# Track statistics\n",
    "label_counts = defaultdict(int)\n",
    "packaging_counts = defaultdict(int)\n",
    "dosage_counts = defaultdict(int)\n",
    "medication_counts = defaultdict(int)\n",
    "unique_labels = set()\n",
    "csv_data = []\n",
    "\n",
    "# Get all image files\n",
    "valid_exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")\n",
    "all_images = [f for f in os.listdir(input_dir) if f.lower().endswith(valid_exts)]\n",
    "\n",
    "for filename in all_images:\n",
    "    old_path = os.path.join(input_dir, filename)\n",
    "    name_wo_ext, ext = os.path.splitext(filename)\n",
    "\n",
    "    # 1) Detect packaging, dosage, version, and augmentation\n",
    "    packaging = determine_packaging(name_wo_ext, priority=priority)\n",
    "    dosages_found = dosage_pattern.findall(name_wo_ext)\n",
    "    dosage_str = \"_\".join(d.strip() for d in dosages_found) if dosages_found else \"UnknownDosage\"\n",
    "    version_match = version_pattern.search(name_wo_ext)\n",
    "    version_str = f\"v{version_match.group(1)}\" if version_match else \"v1\"\n",
    "    aug_match = aug_pattern.search(name_wo_ext)\n",
    "    aug_str = f\"aug{aug_match.group(1)}\" if aug_match else \"aug0\"\n",
    "\n",
    "    # 2) Clean medication name\n",
    "    med_name_cleaned = name_wo_ext\n",
    "    for d in dosages_found:\n",
    "        med_name_cleaned = med_name_cleaned.replace(d, \"\")\n",
    "    if version_match:\n",
    "        med_name_cleaned = med_name_cleaned.replace(version_match.group(0), \"\")\n",
    "    if aug_match:\n",
    "        med_name_cleaned = med_name_cleaned.replace(aug_match.group(0), \"\")\n",
    "    med_name_cleaned = re.sub(r\"\\[.*?\\]\", \"\", med_name_cleaned)\n",
    "    med_name_cleaned = re.sub(r\"\\(.*?\\)\", \"\", med_name_cleaned)\n",
    "    med_name_cleaned = re.sub(r\"\\s+\", \"_\", med_name_cleaned)\n",
    "    med_name_cleaned = re.sub(r\"_+\", \"_\", med_name_cleaned)\n",
    "    med_name_cleaned = re.sub(r\"-+\", \"-\", med_name_cleaned)\n",
    "    med_name_cleaned = med_name_cleaned.strip(\"_- \")\n",
    "    if not med_name_cleaned:\n",
    "        med_name_cleaned = \"UnknownMed\"\n",
    "\n",
    "    # 3) Construct the new filename (you may keep packaging in the name for reference)\n",
    "    new_filename = f\"{med_name_cleaned} - {dosage_str} - {version_str} - {aug_str} - {packaging}{ext}\"\n",
    "\n",
    "    # 4) Create the subdirectory for this class (packaging type) if it doesn't exist\n",
    "    class_dir = os.path.join(output_dir, packaging)\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.makedirs(class_dir)\n",
    "\n",
    "    # 5) Copy the file to its respective class subfolder\n",
    "    new_path = os.path.join(class_dir, new_filename)\n",
    "    copy2(old_path, new_path)\n",
    "\n",
    "    # 6) Update tracking and CSV data\n",
    "    unique_labels.add((med_name_cleaned, dosage_str, version_str, packaging))\n",
    "    label_counts[(med_name_cleaned, dosage_str, packaging)] += 1\n",
    "    packaging_counts[packaging] += 1\n",
    "    dosage_counts[dosage_str] += 1\n",
    "    medication_counts[med_name_cleaned] += 1\n",
    "\n",
    "    csv_data.append([filename, new_filename, med_name_cleaned, dosage_str, version_str, aug_str, packaging])\n",
    "\n",
    "\n",
    "# ============= WRITE CSV =============\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"original_filename\",\"new_filename\",\"medication\",\"dosage\",\"version\",\"augmentation\",\"packaging\"])\n",
    "    writer.writerows(csv_data)\n",
    "\n",
    "# ============= PRINT STATISTICS =============\n",
    "print(f\"Total unique labels (ignoring augmentation): {len(unique_labels)}\")\n",
    "\n",
    "print(\"\\n=== Packaging Counts ===\")\n",
    "for packaging, count in packaging_counts.items():\n",
    "    print(f\"{packaging}: {count} images\")\n",
    "\n",
    "print(\"\\n=== Dosage Counts (Top 10) ===\")\n",
    "for dosage, count in sorted(dosage_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{dosage}: {count}\")\n",
    "\n",
    "print(\"\\n=== Top 10 Medications ===\")\n",
    "for med, count in sorted(medication_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{med}: {count}\")\n",
    "\n",
    "print(\"\\nProcessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= CONFIG =============\n",
    "dataset_path = \"../Dataset/Oral Dose Forms/\"         # Folder with images\n",
    "output_folder = \"../Dataset/Labelled_Images_Iter1/\"  # Output for processed files\n",
    "csv_name = \"./keyword_label_summary.csv\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "if os.path.exists(output_folder):\n",
    "    for filename in os.listdir(output_folder):\n",
    "        file_path = os.path.join(output_folder, filename)\n",
    "        try:\n",
    "            if os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "            else:\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {file_path}: {e}\")\n",
    "else:\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m src_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, image)\n\u001b[1;32m     65\u001b[0m dst_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, new_filename)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mcopy2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# 5) Prepare row for CSV\u001b[39;00m\n\u001b[1;32m     69\u001b[0m summary_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m: image,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m: new_filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackaging\u001b[39m\u001b[38;5;124m\"\u001b[39m: packaging,\n\u001b[1;32m     77\u001b[0m })\n",
      "File \u001b[0;32m~/miniconda3/envs/mlEnv/lib/python3.10/shutil.py:435\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m    434\u001b[0m copyfile(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m--> 435\u001b[0m \u001b[43mcopystat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/miniconda3/envs/mlEnv/lib/python3.10/shutil.py:374\u001b[0m, in \u001b[0;36mcopystat\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    372\u001b[0m     st \u001b[38;5;241m=\u001b[39m lookup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstat\u001b[39m\u001b[38;5;124m\"\u001b[39m)(src, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow)\n\u001b[1;32m    373\u001b[0m mode \u001b[38;5;241m=\u001b[39m stat\u001b[38;5;241m.\u001b[39mS_IMODE(st\u001b[38;5;241m.\u001b[39mst_mode)\n\u001b[0;32m--> 374\u001b[0m \u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mst_atime_ns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mst_mtime_ns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# We must copy extended attributes before the file is (potentially)\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# chmod()'ed read-only, otherwise setxattr() will error with -EACCES.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m _copyxattr(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============= KEYWORD CATEGORIES =============\n",
    "categories = {\n",
    "    \"tabs\":    [\"tab\", \"mg\", \"cap\"],\n",
    "    \"boxes\":   [\"box\", \"pack\", \"pak\"],\n",
    "    \"bottles\": [\"bottle\", \"jar\", \"btl\", \"ml\", \"syrup\", \"powder\", \"g\"]\n",
    "}\n",
    "fallback_category = \"others\"\n",
    "\n",
    "# Track label counts\n",
    "label_counts = {cat: 0 for cat in categories}\n",
    "label_counts[fallback_category] = 0\n",
    "\n",
    "# ============= HELPER: DETERMINE CATEGORY =============\n",
    "def categorize_image(filename: str) -> str:\n",
    "    lower_name = filename.lower()\n",
    "    for cat, keywords in categories.items():\n",
    "        if any(kw in lower_name for kw in keywords):\n",
    "            return cat\n",
    "    return fallback_category\n",
    "\n",
    "# ============= AUGMENTATION PATTERN =============\n",
    "# We'll search for something like \"_aug_2\" and convert it to \"aug2\"\n",
    "aug_pattern = re.compile(r\"_aug_(\\d+)\", re.IGNORECASE)\n",
    "\n",
    "# ============= PARSING LOGIC & FILE PROCESSING =============\n",
    "valid_exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")\n",
    "all_images = [f for f in os.listdir(dataset_path) if f.lower().endswith(valid_exts)]\n",
    "summary_data = []\n",
    "\n",
    "for image in all_images:\n",
    "    category = categorize_image(image)\n",
    "    label_counts[category] += 1\n",
    "\n",
    "    base_name, ext = os.path.splitext(image)\n",
    "    # Example base_name: \"Amoxycillin_500mg_v1_aug_2_Box\"\n",
    "\n",
    "    # 1) Convert any `_aug_X` to `augX` in the base name\n",
    "    #    This ensures a simpler name if you're relying on underscores for splitting.\n",
    "    #    We'll do a find-and-replace on the entire base_name:\n",
    "    updated_base_name = aug_pattern.sub(lambda m: f\"aug{m.group(1)}\", base_name)\n",
    "    # e.g. \"Amoxycillin_500mg_v1_aug_2_Box\" -> \"Amoxycillin_500mg_v1_aug2_Box\"\n",
    "\n",
    "    # 2) Now split by underscores\n",
    "    parts = updated_base_name.split(\"_\")\n",
    "    if len(parts) >= 5:\n",
    "        medication   = parts[0]\n",
    "        dosage       = parts[1]\n",
    "        version      = parts[2]\n",
    "        augmentation = parts[3]\n",
    "        packaging    = parts[4]\n",
    "    else:\n",
    "        # If not enough parts, fill placeholders\n",
    "        medication   = parts[0] if len(parts) > 0 else \"UnknownMed\"\n",
    "        dosage       = parts[1] if len(parts) > 1 else \"UnknownDosage\"\n",
    "        version      = parts[2] if len(parts) > 2 else \"UnknownVer\"\n",
    "        augmentation = parts[3] if len(parts) > 3 else \"UnknownAug\"\n",
    "        packaging    = parts[4] if len(parts) > 4 else category\n",
    "\n",
    "    # 3) Construct new filename\n",
    "    #    e.g. \"<Medication> - <Dosage> - <Version> - <Augmentation> - <Packaging>.ext\"\n",
    "    new_filename = f\"{medication} - {dosage} - {version} - {augmentation} - {packaging}{ext}\"\n",
    "\n",
    "    # 4) Copy (or move) to output\n",
    "    src_path = os.path.join(dataset_path, image)\n",
    "    dst_path = os.path.join(output_folder, new_filename)\n",
    "    copy2(src_path, dst_path)\n",
    "\n",
    "    # 5) Prepare row for CSV\n",
    "    summary_data.append({\n",
    "        \"original_filename\": image,\n",
    "        \"new_filename\": new_filename,\n",
    "        \"medication\": medication,\n",
    "        \"dosage\": dosage,\n",
    "        \"version\": version,\n",
    "        \"augmentation\": augmentation,\n",
    "        \"packaging\": packaging,\n",
    "    })\n",
    "\n",
    "# ============= WRITE CSV & SUMMARY =============\n",
    "df = pd.DataFrame(summary_data)\n",
    "df.to_csv(csv_name, index=False)\n",
    "print(f\"Saved CSV to {csv_name}\")\n",
    "\n",
    "print(\"\\nLabel Counts:\")\n",
    "for cat, ccount in label_counts.items():\n",
    "    print(f\"{cat}: {ccount} images\")\n",
    "\n",
    "print(\"\\nProcessing complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
